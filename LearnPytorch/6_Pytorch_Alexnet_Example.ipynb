{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshwinUnnikrishnan/DeepLearning7150/blob/main/LearnPytorch/6_Pytorch_Alexnet_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay7wCdH-80LL"
      },
      "source": [
        "Pytorch Alexnet Example\n",
        "=======================\n",
        "\n",
        "This is a complete example of training an alexnet on pytorch, fully within notebook, and using nothing but widely-used library functions.\n",
        "\n",
        "Warning: this notebook download a full large-scale dataset (places365).  That is too large to do in a practical way on Google Colab, so you need to host this notebook on your own server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f7y0x1qT80LN"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision, os\n",
        "\n",
        "def train_alexnet_places(num_steps=100000):\n",
        "    print(\"Making alexnet...\")\n",
        "    alexnet = make_untrained_alexnet_places()\n",
        "    alexnet.train()\n",
        "    print(\"Loading datasets...\")\n",
        "    train_loader, val_loader = get_train_and_val_data_loaders()\n",
        "    print(\"Training classifier...\")\n",
        "    checkpointer = make_checkpointing_function(val_loader, checkpoint_dir='checkpoints')\n",
        "    train_classifier(alexnet, train_loader,\n",
        "                     max_iter=num_steps,\n",
        "                     momentum=0.9,\n",
        "                     init_lr=2e-2,\n",
        "                     weight_decay=5e-4,\n",
        "                     monitor=checkpointer)\n",
        "    return alexnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6LdYdIO80LO"
      },
      "source": [
        "# Untrained Alexnet\n",
        "-----------------\n",
        "\n",
        "This function creates an untrained alexnet, with randomized parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xLahZQHZ80LP"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from collections import OrderedDict\n",
        "def make_untrained_alexnet_places():\n",
        "    # channel widths\n",
        "    w = [3, 96, 256, 384, 384, 256, 4096, 4096, 365]\n",
        "    # Alexnet splits channels into groups\n",
        "    groups = [1, 2, 1, 2, 2]\n",
        "    model = nn.Sequential(OrderedDict([\n",
        "        ('conv1', nn.Conv2d(w[0], w[1], kernel_size=11,\n",
        "            stride=4,\n",
        "            groups=groups[0], bias=True)),\n",
        "        ('relu1', nn.ReLU(inplace=True)),\n",
        "        ('pool1', nn.MaxPool2d(kernel_size=3, stride=2)),\n",
        "        ('conv2', nn.Conv2d(w[1], w[2], kernel_size=5, padding=2,\n",
        "            groups=groups[1], bias=True)),\n",
        "        ('relu2', nn.ReLU(inplace=True)),\n",
        "        ('pool2', nn.MaxPool2d(kernel_size=3, stride=2)),\n",
        "        ('conv3', nn.Conv2d(w[2], w[3], kernel_size=3, padding=1,\n",
        "            groups=groups[2], bias=True)),\n",
        "        ('relu3', nn.ReLU(inplace=True)),\n",
        "        ('conv4', nn.Conv2d(w[3], w[4], kernel_size=3, padding=1,\n",
        "            groups=groups[3], bias=True)),\n",
        "        ('relu4', nn.ReLU(inplace=True)),\n",
        "        ('conv5', nn.Conv2d(w[4], w[5], kernel_size=3, padding=1,\n",
        "            groups=groups[4], bias=True)),\n",
        "        ('relu5', nn.ReLU(inplace=True)),\n",
        "        ('pool5', nn.MaxPool2d(kernel_size=3, stride=2)),\n",
        "        ('flatten', nn.Flatten()),\n",
        "        ('fc6', nn.Linear(w[5] * 6 * 6, w[6], bias=True)),\n",
        "        ('relu6', nn.ReLU(inplace=True)),\n",
        "        ('dropout6', nn.Dropout()),\n",
        "        ('fc7', nn.Linear(w[6], w[7], bias=True)),\n",
        "        ('relu7', nn.ReLU(inplace=True)),\n",
        "        ('dropout7', nn.Dropout()),\n",
        "        ('fc8', nn.Linear(w[7], w[8]))\n",
        "    ]))\n",
        "    # Setup the initial parameters randomly\n",
        "    for n, p in model.named_parameters():\n",
        "        if 'bias' in n:\n",
        "            torch.nn.init.zeros_(p)\n",
        "        else:\n",
        "            torch.nn.init.kaiming_normal_(p, nonlinearity='relu')\n",
        "    model.cuda()\n",
        "    model.train()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf8zM5FX80LP"
      },
      "source": [
        "We can call the function to make a network, and then list all the network's trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgRwZlIw80LQ",
        "outputId": "a29d859c-fded-475b-e672-ba024596c33d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight (96, 3, 11, 11)\n",
            "conv1.bias (96,)\n",
            "conv2.weight (256, 48, 5, 5)\n",
            "conv2.bias (256,)\n",
            "conv3.weight (384, 256, 3, 3)\n",
            "conv3.bias (384,)\n",
            "conv4.weight (384, 192, 3, 3)\n",
            "conv4.bias (384,)\n",
            "conv5.weight (256, 192, 3, 3)\n",
            "conv5.bias (256,)\n",
            "fc6.weight (4096, 9216)\n",
            "fc6.bias (4096,)\n",
            "fc7.weight (4096, 4096)\n",
            "fc7.bias (4096,)\n",
            "fc8.weight (365, 4096)\n",
            "fc8.bias (365,)\n"
          ]
        }
      ],
      "source": [
        "a = make_untrained_alexnet_places()\n",
        "for n, p in a.named_parameters():\n",
        "    print(n, tuple(p.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbH7PX8-80LQ"
      },
      "source": [
        "And we can save the uninitialized neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "myXmScTM80LQ"
      },
      "outputs": [],
      "source": [
        "torch.save(a.state_dict(), 'uninitialized_alexnet.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_IfSEBZ80LQ"
      },
      "source": [
        "Main Training Loop\n",
        "------------------\n",
        "\n",
        "This is a generic training loop for a classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gdna2cYz80LR"
      },
      "outputs": [],
      "source": [
        "def train_classifier(model, train_data_loader, max_iter,\n",
        "                     momentum=0.9, init_lr=2e-2, weight_decay=5e-4,\n",
        "                     monitor=None):\n",
        "    if monitor is not None:\n",
        "        monitor(model, 0, 0.0, 0.0, 0)\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=init_lr, momentum=momentum, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, init_lr, max_iter)\n",
        "    iter_num = 0\n",
        "    while iter_num < max_iter:\n",
        "        for t_input, t_target in train_data_loader:\n",
        "            # Copy data into the gpu\n",
        "            input_var, target_var = [d.cuda() for d in [t_input, t_target]]\n",
        "            # Evaluate model\n",
        "            output = model(input_var)\n",
        "            loss = torch.nn.functional.cross_entropy(output, target_var)\n",
        "            # Perform one step of SGD\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step() # Learning rate schedule\n",
        "            # Check training set accuracy\n",
        "            _, pred = output.max(1)\n",
        "            batch_size = len(t_input)\n",
        "            accuracy = target_var.detach().eq(pred).float().sum().item() / batch_size\n",
        "            # Advance, and print out some stats\n",
        "            iter_num += 1\n",
        "            if monitor is not None:\n",
        "                monitor(model, iter_num, loss, accuracy, batch_size)\n",
        "            if iter_num >= max_iter:\n",
        "                break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk8sZ-Yi80LR"
      },
      "source": [
        "Data set\n",
        "--------\n",
        "\n",
        "This is the definition of the places data set used for training.\n",
        "If we do not have the files, we download them.  And then we make a\n",
        "DataSet object that defines how to resize, crop, and normalize the images.\n",
        "\n",
        "The DataLoader objects wrap the dataset in a multithreaded streaming\n",
        "object that batches the image data and loads it quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h-AbvDE980LS"
      },
      "outputs": [],
      "source": [
        "def get_places_data_set(split, crop_size=227, download=True):\n",
        "    dirname = f'datasets/places/{split}'\n",
        "    nfs_source = '/data/vision/torralba/datasets/places/files'\n",
        "    web_source = 'https://dissect.csail.mit.edu/datasets/'\n",
        "    if not os.path.exists(dirname) and download:\n",
        "        if os.path.exists(nfs_source):\n",
        "            os.symlink(nfs_source, 'datasets/places')\n",
        "        else:\n",
        "            os.makedirs(dirname, exist_ok=True)\n",
        "            torchvision.datasets.utils.download_and_extract_archive(\n",
        "                'web_sources' +\n",
        "                'places_%s.zip' % split,\n",
        "                'datasets',\n",
        "                md5=dict(val='593bbc21590cf7c396faac2e600cd30c',\n",
        "                         train='d1db6ad3fc1d69b94da325ac08886a01')[split])\n",
        "    if split == 'train':\n",
        "        cropping_rule = [\n",
        "            torchvision.transforms.RandomCrop(227),\n",
        "            torchvision.transforms.RandomHorizontalFlip() ]\n",
        "    else:\n",
        "        cropping_rule = [torchvision.transforms.CenterCrop(crop_size)]\n",
        "    places_transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(256)\n",
        "        ] + cropping_rule + [\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(\n",
        "            [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    return torchvision.datasets.ImageFolder(\n",
        "        dirname, transform=places_transform)\n",
        "\n",
        "def get_train_and_val_data_loaders():\n",
        "    return [\n",
        "        torch.utils.data.DataLoader(\n",
        "            get_places_data_set(split),\n",
        "            batch_size=256, shuffle=(split == 'train'),\n",
        "            num_workers=48, pin_memory=True)\n",
        "        for split in ['train', 'val']\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eknQ1w-V80LS"
      },
      "source": [
        "Generic Evaluation and Checkpointing Utilities\n",
        "----------------------------------------------\n",
        "\n",
        " * **measure_val_accuracy_and_loss** evaluates the model on the holdout set and reports its performance.\n",
        " * **save_model_iteration** saves the current model parameters in a pytorch file.\n",
        " * **make_training_monitor** makes a callback function for periodically evaluating and saving a model during training.\n",
        " * **AverageMeter** tracks averages (e.g., average accuracy, average loss)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "66ueJNFB80LS"
      },
      "outputs": [],
      "source": [
        "def measure_val_accuracy_and_loss(model, val_data_loader):\n",
        "    '''\n",
        "    Evaluates the model (in inference mode) on holdout data.\n",
        "    '''\n",
        "    model.eval()\n",
        "    val_loss, val_acc = AverageMeter(), AverageMeter()\n",
        "    for input, target in val_data_loader:\n",
        "        input_var, target_var = [d.cuda() for d in [input, target]]\n",
        "        with torch.no_grad():\n",
        "            output = model(input_var)\n",
        "            loss = torch.nn.functional.cross_entropy(output, target_var)\n",
        "            _, pred = output.max(1)\n",
        "            accuracy = (target_var.eq(pred)\n",
        "                    ).data.float().sum().item() / input.size(0)\n",
        "        val_acc.update(accuracy, input.size(0))\n",
        "        val_loss.update(loss.data.item(), input.size(0))\n",
        "    return val_acc, val_loss\n",
        "\n",
        "def save_model_iteration(model, iter_num, checkpoint_dir):\n",
        "    '''\n",
        "    Saves the current parameters of the model to a file.\n",
        "    '''\n",
        "    torch.save(model.state_dict(), os.path.join(checkpoint_dir, f'iter_{iter_num}.pth'))\n",
        "        \n",
        "def make_checkpointing_function(val_data_loader, checkpoint_dir=None, checkpoint_freq=100):\n",
        "    '''\n",
        "    Makes a callback to monitor training and make checkpoints.\n",
        "    '''\n",
        "    avg_train_accuracy, avg_train_loss = AverageMeter(), AverageMeter()\n",
        "    def monitor(model, iter_num, loss, accuracy, batch_size):\n",
        "        avg_train_accuracy.update(accuracy, batch_size)\n",
        "        avg_train_loss.update(loss, batch_size)\n",
        "        if iter_num % checkpoint_freq == 0:\n",
        "            val_accuracy, val_loss = measure_val_accuracy_and_loss(model, val_data_loader)\n",
        "            if checkpoint_dir is not None:\n",
        "                save_model_iteration(model, iter_num, checkpoint_dir)\n",
        "            print(f'Iter {iter_num}, ' + \n",
        "                  f'train acc {avg_train_accuracy.avg:.3g} loss {avg_train_loss.avg:.3g}, ' +\n",
        "                  f'val acc {val_accuracy.avg:.3g}, loss {val_loss.avg:.3g}')\n",
        "            model.train()\n",
        "    return monitor            \n",
        "            \n",
        "class AverageMeter(object):\n",
        "    '''\n",
        "    To keep running averages.\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.val = 0.\n",
        "        self.avg = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        if self.count:\n",
        "            self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8FmE9EL80LT"
      },
      "source": [
        "Now do the work\n",
        "---------------\n",
        "\n",
        "Try loading alexnet from a checkpoint.  If we have not yet saved a checkpoint snapshot with the number of iterations we want, then train it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "EIHZSspc80LT",
        "outputId": "3786cc41-6e07-4234-9a49-dcd1471030b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making alexnet...\n",
            "Loading datasets...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a574a25d6909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_untrained_alexnet_places\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'iter_{num_iterations}.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'iter_100.pth'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a574a25d6909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'iter_{num_iterations}.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_alexnet_places\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-0d2992d576f9>\u001b[0m in \u001b[0;36mtrain_alexnet_places\u001b[0;34m(num_steps)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0malexnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading datasets...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_and_val_data_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training classifier...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_checkpointing_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-f66a036d93d0>\u001b[0m in \u001b[0;36mget_train_and_val_data_loaders\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             num_workers=48, pin_memory=True)\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     ]\n",
            "\u001b[0;32m<ipython-input-12-f66a036d93d0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             num_workers=48, pin_memory=True)\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     ]\n",
            "\u001b[0;32m<ipython-input-12-f66a036d93d0>\u001b[0m in \u001b[0;36mget_places_data_set\u001b[0;34m(split, crop_size, download)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;34m'datasets'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 md5=dict(val='593bbc21590cf7c396faac2e600cd30c',\n\u001b[0;32m---> 15\u001b[0;31m                          train='d1db6ad3fc1d69b94da325ac08886a01')[split])\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         cropping_rule = [\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# expand redirect chain if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_redirect_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_hops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_redirect_hops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m# check if file is located on Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_get_redirect_url\u001b[0;34m(url, max_hops)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_hops\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, url, data, headers, origin_req_host, unverifiable, method)\u001b[0m\n\u001b[1;32m    326\u001b[0m                  \u001b[0morigin_req_host\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munverifiable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                  method=None):\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munredirected_hdrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mfull_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeleter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown url type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplithost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: unknown url type: 'web_sourcesplaces_train.zip'"
          ]
        }
      ],
      "source": [
        "num_iterations = 100\n",
        "try:\n",
        "    a = make_untrained_alexnet_places()\n",
        "    a.load_state_dict(torch.load(f'iter_{num_iterations}.pth'))\n",
        "except:\n",
        "    a = train_alexnet_places(num_iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCHMNzaq80LT"
      },
      "source": [
        "Now view one image - reverse the dataset normalization to get a nice image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyCnK43W80LT"
      },
      "outputs": [],
      "source": [
        "dsv = get_places_data_set('val')\n",
        "im, label = dsv[5000]\n",
        "im = im.cuda()\n",
        "# Reverse the normalization\n",
        "unnormalized = (im.cpu().permute(1, 2, 0)\n",
        "    * torch.tensor([0.229, 0.224, 0.225])\n",
        "    + torch.tensor([0.485, 0.456, 0.406]))\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(unnormalized)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxUXvU4x80LT"
      },
      "source": [
        "Finally, run the network on the function and print the prediction.\n",
        "\n",
        "Note the network expexts to work in batches, so `im[None]` forms an image batch of size one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zO244pep80LU"
      },
      "outputs": [],
      "source": [
        "a.eval()\n",
        "output = a(im[None])\n",
        "pred = output.max(1)[1][0]\n",
        "\n",
        "print('prediction: ', dsv.classes[pred])\n",
        "print('groundtruth: ', dsv.classes[label])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}